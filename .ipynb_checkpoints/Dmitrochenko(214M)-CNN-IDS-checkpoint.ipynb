{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('EdgeIIoT Lab + Test.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Attack_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "drop_columns = [\"frame.time\", \"ip.src_host\", \"ip.dst_host\", \"arp.src.proto_ipv4\",\"arp.dst.proto_ipv4\", \n",
    "                \"http.file_data\",\"http.request.full_uri\",\"icmp.transmit_timestamp\",\n",
    "                \"http.request.uri.query\", \"tcp.options\",\"tcp.payload\",\"tcp.srcport\",\n",
    "                \"tcp.dstport\", \"udp.port\", \"mqtt.msg\"]\n",
    "\n",
    "df.drop(drop_columns, axis=1, inplace=True)\n",
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "df.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "print(df['Attack_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Attack_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df)\n",
    "assert df.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "    \n",
    "encode_text_dummy(df,'http.request.method')\n",
    "encode_text_dummy(df,'http.referer')\n",
    "encode_text_dummy(df,\"http.request.version\")\n",
    "encode_text_dummy(df,\"dns.qry.name.len\")\n",
    "encode_text_dummy(df,\"mqtt.conack.flags\")\n",
    "encode_text_dummy(df,\"mqtt.protoname\")\n",
    "encode_text_dummy(df,\"mqtt.topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_dataset.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessed_dataset.csv', low_memory=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks = {'Normal': 0 ,'Backdoor' :1, 'DDoS_HTTP':2,  'DDoS_ICMP':3, 'DDoS_TCP':4, 'DDoS_UDP':5, \n",
    "           'Fingerprinting':6, 'MITM':7, 'Password':8, 'Port_Scanning':9, 'Ransomware':10, \n",
    "           'SQL_injection':11, 'Uploading':12, 'Vulnerability_scanner':13, 'XSS':14}\n",
    "\n",
    "df['Attack_type'] = df['Attack_type'].map(attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = list(df.columns)\n",
    "label_col = \"Attack_type\"\n",
    "feat_cols.remove(label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_cols = [col for col in df.columns if df[col].isnull().all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_list = [\"icmp.unused\", \"http.tls_port\", \"dns.qry.type\", \"mqtt.msg_decoded_as\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[skip_list[3]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, (ax1, ax2)  = plt.subplots(nrows=1, ncols=2, figsize=(12,8))\n",
    "explode = list((np.array(list(df[label_col].dropna().value_counts()))/sum(list(df[label_col].dropna().value_counts())))[::-1])[:]\n",
    "labels = list(df[label_col].dropna().unique())[:]\n",
    "sizes = df[label_col].value_counts()[:]\n",
    "\n",
    "ax2.pie(sizes,  explode=explode, startangle=60, labels=labels, autopct='%1.0f%%', pctdistance=0.8)\n",
    "ax2.add_artist(plt.Circle((0,0),0.4,fc='white'))\n",
    "sns.countplot(y=label_col, data=df, ax=ax1)\n",
    "ax1.set_title(\"Количество атак по типам\")\n",
    "ax2.set_title(\"Процент по типам атак\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_type = df.pop('Attack_type')\n",
    "attack_label = df.pop('Attack_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_counts = attack_type.map({v: k for k, v in attacks.items()}).value_counts()\n",
    "\n",
    "for attack, code in attacks.items():\n",
    "    count = attack_counts[attack] if attack in attack_counts else 0\n",
    "    print(f'{code} - {attack} \\t\\t\\t- {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#X = StandardScaler().fit_transform(df.values)\n",
    "X = df.values\n",
    "y = attack_type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_us, X_test_us, y_train_us, y_test_us = train_test_split(X_res, y_res, stratify=y_res, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "del X\n",
    "del X_res\n",
    "del y\n",
    "del y_res\n",
    "\n",
    "print (\"Train:\", X_train.shape, y_train.shape)\n",
    "print (\"Test:\", X_test.shape, y_test.shape)\n",
    "print (\"Undersampling Train:\", X_train_us.shape, y_train_us.shape)\n",
    "print (\"Undersampling Test:\", X_test_us.shape, y_test_us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the X_train data, count the number attacks of each type\n",
    "unique, counts = np.unique(y_train_us, return_counts=True)\n",
    "print(\"Train: \", dict(zip(unique, counts)))\n",
    "\n",
    "# Do the same for the test data\n",
    "unique, counts = np.unique(y_test_us, return_counts=True)\n",
    "print(\"Test: \", dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train =  label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "y_train_us =  label_encoder.fit_transform(y_train_us)\n",
    "y_test_us = label_encoder.transform(y_test_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train =  min_max_scaler.fit_transform(X_train)\n",
    "X_test = min_max_scaler.transform(X_test)\n",
    "X_train_us =  min_max_scaler.fit_transform(X_train_us)\n",
    "X_test_us = min_max_scaler.transform(X_test_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train_us.shape)\n",
    "print(X_test_us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "X_train_us = X_train_us.reshape(X_train_us.shape[0], X_train_us.shape[1], 1)\n",
    "X_test_us = X_test_us.reshape(X_test_us.shape[0], X_test_us.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train_us.shape)\n",
    "print(X_test_us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_us = X_train_us.shape[1:]\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_us.shape, X_test_us.shape, X_train.shape, X_test.shape)\n",
    "print(input_shape_us)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes_us = len(np.unique(y_train_us))\n",
    "num_classes = len(np.unique(y_train))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tensorflow.keras.utils import to_categorical \n",
    "\n",
    "y_train_us = to_categorical(y_train_us, num_classes=num_classes)\n",
    "y_test_us = to_categorical(y_test_us, num_classes=num_classes)\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_us.shape, y_test_us.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, 3, activation='relu', input_shape=(input_shape)))\n",
    "model.add(MaxPooling1D(2))\n",
    "\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(input_shape)))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Input, ZeroPadding1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Add, AveragePooling1D\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss= tf.keras.metrics.categorical_crossentropy, \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=10)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, mode=\"min\", verbose=1, min_lr=0)\n",
    "call_backs = [early_stopping, lr_reduce]\n",
    "EPOCHS_US = 30\n",
    "BATCH_SIZE = 256\n",
    "call_backs = [early_stopping, lr_reduce]\n",
    "history = model.fit(X_train_us, y_train_us, \n",
    "                    validation_data=(X_test_us, y_test_us),\n",
    "                    validation_split=0.1,\n",
    "                    epochs=EPOCHS_US, \n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=call_backs,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Минимум функции потерь: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_us = model.predict(X_test_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision recall curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "for i in range(num_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test_us[:, i],\n",
    "                                                        y_hat_us[:, i])\n",
    "    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
    "    \n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"precision vs. recall curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_us[:, i], y_hat_us[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(num_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_us = np.argmax(y_test_us, axis=1)\n",
    "y_hat_us = np.argmax(y_hat_us, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def print_score(y_pred_us, y_real_us, labels=label_encoder):\n",
    "    print(\"Точность: \", accuracy_score(y_real_us, y_pred_us))\n",
    "print_score(y_hat_us, y_true_us, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rounded_us=np.argmax(y_test_us, axis=1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cnn_cm_us = confusion_matrix(y_rounded_us, y_hat_us)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cnn_cm_us, display_labels=None)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"CNN Classification Report: \")\n",
    "print(classification_report(y_rounded_us, y_hat_us))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 12\n",
    "BATCH_SIZE = 256\n",
    "call_backs = [early_stopping, lr_reduce]\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    validation_split=0.1,\n",
    "                    epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=call_backs,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Минимум функции потерь: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_hat = np.argmax(y_hat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def print_score(y_pred, y_real, labels=label_encoder):\n",
    "    print(\"Точность: \", accuracy_score(y_real, y_pred))\n",
    "print_score(y_hat, y_true, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rounded=np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cnn_cm = confusion_matrix(y_rounded, y_hat)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cnn_cm, display_labels=None)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"CNN Classification Report: \")\n",
    "print(classification_report(y_rounded, y_hat))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1870444,
     "sourceId": 3319673,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30445,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
